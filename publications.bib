
@inproceedings{
bashiri2025learning,
title={Learning and aligning single-neuron invariance manifolds in visual cortex},
author={Mohammad Bashiri and Luca Baroni and J{\'a}n Antol{\'\i}k and Fabian H. Sinz},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=kbjJ9ZOakb},
note={equal-contribution: Mohammad Bashiri, Luca Baroni}, 
presentation={ICLR ORAL}
}

@article{berling2024optogenetic,
  title={Optogenetic stimulation recruits cortical neurons in a morphology-dependent manner},
  author={Berling, David and Baroni, Luca and Chaffiol, Antoine and Gauvain, Gregory and Picaud, Serge and Antol{\'\i}k, J{\'a}n},
  journal={Journal of Neuroscience},
  volume={44},
  number={49},
  year={2024},
  publisher={Society for Neuroscience},
  url={https://www.jneurosci.org/content/44/49/e1215242024}
}

@InProceedings{pmlr-v197-baroni23a,
  title = 	 {Learning invariance manifolds of visual sensory neurons},
  author =       {Baroni, Luca and Bashiri, Mohammad and Willeke, Konstantin F. and Antol{\'i}k, J{\'a}n and Sinz, Fabian H.},
  booktitle = 	 {Proceedings of the 1st NeurIPS Workshop on Symmetry and Geometry in Neural Representations},
  pages = 	 {301--326},
  year = 	 {2023},
  editor = 	 {Sanborn, Sophia and Shewmake, Christian and Azeglio, Simone and Di Bernardo, Arianna and Miolane, Nina},
  volume = 	 {197},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {03 Dec},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v197/baroni23a/baroni23a.pdf},
  url = 	 {https://proceedings.mlr.press/v197/baroni23a.html},
  abstract = 	 {Robust object recognition is thought to rely on neural mechanisms that are selective to complex stimulus features while being invariant to others (e.g., spatial location or orientation). To better understand biological vision, it is thus crucial to characterize which features neurons in different visual areas are selective or invariant to. In the past, invariances have commonly been identified by presenting carefully selected hypothesis-driven stimuli which rely on the intuition of the researcher. One example is the discovery of phase invariance in V1 complex cells. However, to identify novel invariances, a data-driven approach is more desirable. Here, we present a method that, combined with a predictive model of neural responses, learns a manifold in the stimulus space along which a target neuronâ€™s response is invariant. Our approach is fully data-driven, allowing the discovery of novel neural invariances, and enables scientists to generate and experiment with novel stimuli along the invariance manifold. We test our method on Gabor-based neuron models as well as on a neural network fitted on macaque V1 responses and show that 1) it successfully identifies neural invariances, and 2) disentangles invariant directions in the stimulus space.}
  note = {equal-contribution: Mohammad Bashiri, Luca Baroni}, 
}


@misc{baroni2025transformersdontneedlayernorm,
      title={Transformers don't need LayerNorm at inference time: scaling LayerNorm removal to GPT-2 XL and the implications for mechanistic interpretability}, 
      author={Luca Baroni and Galvin Khara and Joachim Schaeffer and Marat Subkhankulov and Stefan Heimersheim},
      year={2025},
      eprint={2507.02559},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2507.02559}, 
      note={equal-contribution: Luca Baroni, Galvin Khara, Joachim Schaeffer, Marat Subkhankulov},
      presentation={}
}

@article {Ding2023.03.15.532836,
	author = {Ding, Zhiwei and Tran, Dat T. and Ponder, Kayla and Ding, Zhuokun and Froebe, Rachel and Ntanavara, Lydia and Fahey, Paul G. and Cobos, Erick and Baroni, Luca and Diamantaki, Maria and Wang, Eric Y. and Chang, Andersen and Papadopoulos, Stelios and Fu, Jiakun and Muhammad, Taliah and Papadopoulos, Christos and Cadena, Santiago A. and Evangelou, Alexandros and Willeke, Konstantin and Anselmi, Fabio and Sanborn, Sophia and Antolik, Jan and Froudarakis, Emmanouil and Patel, Saumil and Walker, Edgar Y. and Reimer, Jacob and Sinz, Fabian H. and Ecker, Alexander S. and Franke, Katrin and Pitkow, Xaq and Tolias, Andreas S.},
	title = {Bipartite invariance in mouse primary visual cortex},
	elocation-id = {2023.03.15.532836},
	year = {2025},
	doi = {10.1101/2023.03.15.532836},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {A primary goal of sensory systems is to extract robust and meaningful features that are invariant to variations in the sensory input. Characterizing these invariances at the neuronal level is crucial for understanding how the visual system supports generalization, but the high-dimensional nature of ecological stimuli poses major challenges. Consequently, our understanding of how the brain represents invariances has historically depended on a few examples, such as phase invariance to grating stimuli in V1 complex cells. Here, we leverage the inception loop paradigm {\textemdash}iterating between large-scale recordings, deep learning neuronal predictive models, and in silico experiments with in vivo verification{\textemdash}to characterize neuronal invariances in mouse V1. Using a neuronal predictive model, we synthesized Diverse Exciting Inputs (DEIs) that strongly drive target neurons while differing substantially in image space. These DEIs revealed a novel bipartite invariance: one portion of the receptive field encodes shift-invariant, high-frequency textures, while the other encodes a fixed, low-frequency spatial pattern. This subfield division aligned with object boundaries defined by spatial frequency differences in highly activating stimuli, suggesting bi-partite invariance contributes to segmentation. Our analysis of computational models and anatomical data from the MICrONS dataset revealed a hierarchical organization of excitatory neurons in mouse V1 Layers 2/3: We found that postsynaptic neurons exhibited greater invariance than their presynaptic inputs, while neurons with lower invariance formed more connections. These findings suggest a synaptic-level hierarchy that progressively increases neural invariance within the primary visual cortex. Intriguingly, similar high-low frequency bipartite patterns strongly activate certain units in artificial neural networks, suggesting that universal visual representations govern both biological and artificial systems, potentially aiding in the extraction of visual features from complex backgrounds.Competing Interest StatementXP is a co-founder of Upload AI, LLC, a company in which he has financial interests. AST is a co-founder of Vathes Inc., and UploadAI LLC companies in which he has financial interests. JR is a co-founder of Vathes Inc., and UploadAI LLC companies in which he has financial interests.},
	URL = {https://www.biorxiv.org/content/early/2025/04/19/2023.03.15.532836},
	eprint = {https://www.biorxiv.org/content/early/2025/04/19/2023.03.15.532836.full.pdf},
	journal = {bioRxiv}
}


@article {Fu2023.03.13.532473,
	author = {Fu, Jiakun and Shrinivasan, Suhas and Baroni, Luca and Ding, Zhuokun and Fahey, Paul G. and Pierzchlewicz, Pawe{\l} A. and Ponder, Kayla and Froebe, Rachel and Ntanavara, Lydia and Muhammad, Taliah and Willeke, Konstantin F. and Wang, Eric and Ding, Zhiwei and Tran, Dat T. and Papadopoulos, Stelios and Patel, Saumil and Reimer, Jacob and Ecker, Alexander S. and Pitkow, Xaq and Antolik, Jan and Sinz, Fabian H. and H{\"a}fner, Ralf M. and Tolias, Andreas S. and Franke, Katrin},
	title = {Pattern completion and disruption characterize contextual modulation in the visual cortex},
	elocation-id = {2023.03.13.532473},
	year = {2024},
	doi = {10.1101/2023.03.13.532473},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Vision is fundamentally context-dependent, with neuronal responses influenced not just by local features but also by surrounding contextual information. In the visual cortex, studies using simple grating stimuli indicate that congruent stimuli{\textemdash}where the center and surround share the same orientation{\textemdash}are more inhibitory than when orientations are orthogonal, potentially serving redundancy reduction and predictive coding. Understanding these center-surround interactions in relation to natural image statistics is challenging due to the high dimensionality of the stimulus space, yet crucial for deciphering the neuronal code of real-world sensory processing. Utilizing large-scale recordings from mouse V1, we trained convolutional neural networks (CNNs) to predict and synthesize surround patterns that either optimally suppressed or enhanced responses to center stimuli, confirmed by in v ivo experiments. Contrary to the notion that congruent stimuli are suppressive, we found that surrounds that completed patterns based on natural image statistics were facilitatory, while disruptive surrounds were suppressive. Applying our CNN image synthesis method in macaque V1, we discovered that pattern completion within the near surround occurred more frequently with excitatory than with inhibitory surrounds, suggesting that our results in mice are conserved in macaques. Further, experiments and model analyses confirmed previous studies reporting the opposite effect with grating stimuli in both species. Using the MICrONS functional connectomics dataset, we observed that neurons with similar feature selectivity formed excitatory connections regardless of their receptive field overlap, aligning with the pattern completion phenomenon observed for excitatory surrounds. Finally, our empirical results emerged in a normative model of perception implementing Bayesian inference, where neuronal responses are modulated by prior knowledge of natural scene statistics. In summary, our findings identify a novel relationship between contextual information and natural scene statistics and provide evidence for a role of contextual modulation in hierarchical inference.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2024/05/09/2023.03.13.532473},
	eprint = {https://www.biorxiv.org/content/early/2024/05/09/2023.03.13.532473.full.pdf},
	journal = {bioRxiv}
  note={equal-contribution: Suhas Shrinivasan, Luca Baroni}, 
}
